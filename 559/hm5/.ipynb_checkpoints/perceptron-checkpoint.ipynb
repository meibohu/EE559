{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import csv\n",
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 13)\n",
      "(13,)\n",
      "mean of unnormalized data points is: \n",
      "[1.2965391e+01 2.2699997e+00 2.3762920e+00 1.9649437e+01 9.8910110e+01\n",
      " 2.2723591e+00 2.0294383e+00 3.6067417e-01 1.5761796e+00 5.0912361e+00\n",
      " 9.5321345e-01 2.5603375e+00 7.2970789e+02]\n",
      "standard deviation of unnormalized data points is: \n",
      "[8.1956011e-01 1.1030642e+00 2.7300403e-01 3.4651763e+00 1.1558973e+01\n",
      " 6.1454839e-01 9.1971827e-01 1.2024129e-01 5.4147017e-01 2.4043779e+00\n",
      " 2.2990756e-01 7.2346151e-01 3.0722125e+02]\n",
      "After standardization:\n",
      "[[ 0.957351   -0.48954538  0.12347054 ...  0.85593736  0.46949705\n",
      "   1.9213911 ]\n",
      " [ 0.28625914 -0.44421718 -0.86552584 ...  0.4209799   1.1606189\n",
      "   1.0425457 ]\n",
      " [ 0.12763734 -0.69805545 -1.0120445  ...  0.9864245   0.17922582\n",
      "   0.94489616]\n",
      " ...\n",
      " [-0.5312526   2.9372725   0.965949   ... -0.57942194 -1.2030177\n",
      "  -0.6988706 ]\n",
      " [-0.10419382  0.65272725  0.08684108 ... -0.9273878  -1.5762236\n",
      "  -0.6500458 ]\n",
      " [ 0.93294716  1.8947222  -0.42597228 ... -0.753405   -1.1200832\n",
      "  -0.6825957 ]]\n"
     ]
    }
   ],
   "source": [
    "with open('wine_train.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "\n",
    "#print(np.shape(data))\n",
    "\n",
    "data_array = np.asarray(data, dtype=np.float32)\n",
    "data_unnorm = copy.deepcopy(data_array)\n",
    "\n",
    "data_fea_unnorm = data_unnorm[:,0:13]\n",
    "print(np.shape(data_fea_unnorm))\n",
    "mean_unnorm = np.mean(data_fea_unnorm, axis = 0)\n",
    "std_unnorm = np.std(data_fea_unnorm, axis = 0)\n",
    "print(np.shape(mean_unnorm))\n",
    "print(\"mean of unnormalized data points is: \") \n",
    "print(mean_unnorm)\n",
    "print(\"standard deviation of unnormalized data points is: \") \n",
    "print(std_unnorm)\n",
    "\n",
    "data_fea_norm = copy.deepcopy(data_fea_unnorm)\n",
    "sc_X = StandardScaler()\n",
    "sc_X.fit(data_fea_norm)  #the normalizing factors should be calculated from the training data only\n",
    "data_fea_norm = sc_X.transform(data_fea_norm)     #\tFit to data, then transform it.\n",
    "print('After standardization:') \n",
    "print(data_fea_norm)\n",
    "#print(np.shape(data_fea_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 2)\n",
      "(89,)\n"
     ]
    }
   ],
   "source": [
    "#take first tow columns\n",
    "feature_2 = data_fea_norm[:,0:2]\n",
    "print(np.shape(feature_2))\n",
    "class_labels = data_unnorm[:,13]\n",
    "print(np.shape(class_labels))\n",
    "#print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_2's final Weight:\n",
      "[[ 2.56236516 -0.78871346]\n",
      " [-2.80638263 -2.11229876]\n",
      " [ 1.37876909  1.5411631 ]]\n",
      "mean accuracy is 0.797752808988764\n"
     ]
    }
   ],
   "source": [
    "def calcul_accuracy(real_label, pre_label):\n",
    "    cnt = 0\n",
    "    for i in range(len(real_label)):\n",
    "        if real_label[i] == pre_label[i]:\n",
    "            cnt += 1\n",
    "    return cnt/len(real_label)\n",
    "\n",
    "#perceptron on the first two features\n",
    "perceptron = Perceptron(max_iter=1000, tol=0.0001, random_state = None) \n",
    "perceptron.fit(feature_2, class_labels) #fit(X, y[, coef_init, intercept_init, ...])\tFit linear model with Stochastic Gradient Descent. \n",
    "print(\"feature_2's final Weight:\")\n",
    "#print(perceptron.intercept_)             #不懂\n",
    "final_wei1 = perceptron.coef_\n",
    "print(final_wei1)\n",
    "\n",
    "label_train_pred1 = perceptron.predict(feature_2)      #Predict class labels for samples in X.\n",
    "#print(label_train_pred1)\n",
    "mean_ar = perceptron.score(feature_2, class_labels)\n",
    "#print(mean_ar)\n",
    "mean_accuracy1 = calcul_accuracy(class_labels, label_train_pred1)    #Returns the mean accuracy on the given test data and labels.\n",
    "print(\"mean accuracy is \" + str(mean_accuracy1))\n",
    "\n",
    "#print(calcul_accuracy(label_train_pred1, class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_all's final Weight:\n",
      "[[ 2.96788298  1.57742418  4.31404927 -2.77139503  1.94313723 -1.21364307\n",
      "   3.35605998 -2.71084106 -0.61484706 -1.09075367  3.30254799  2.40789942\n",
      "   6.29594261]\n",
      " [-4.8899878  -3.97982317 -3.19499743  2.16342021 -2.12296724 -1.76689468\n",
      "  -0.85175116  1.69696185  0.770271   -7.80350854  2.41523474 -0.19071857\n",
      "  -5.76702636]\n",
      " [ 2.23578269  1.54116194  2.62909292  0.51848108  2.63524008 -1.44145373\n",
      "  -3.82005122 -2.37817672 -2.31392536  4.6986853  -4.59627768 -2.65111257\n",
      "  -0.73482172]]\n",
      "mean accuracy is 1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "###all features\n",
    "perceptron.fit(data_fea_norm, class_labels)\n",
    "print(\"feature_all's final Weight:\")\n",
    "\n",
    "final_wei2 = perceptron.coef_\n",
    "print(final_wei2)\n",
    "label_train_pred2 = perceptron.predict(data_fea_norm)      #Predict class labels for samples in X.\n",
    "#print(label_train_pred2)\n",
    "mean_accuracy2 = calcul_accuracy(label_train_pred2, class_labels)\n",
    "print(\"mean accuracy is \" + str(mean_accuracy2))\n",
    "#mean_ar2 = perceptron.score(data_fea_norm, class_labels)\n",
    "print(mean_ar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 13)\n",
      "After standardization:\n",
      "[[ 1.5308298   1.5592928   0.48976514 ... -0.2749518   1.3403103\n",
      "   0.0986004 ]\n",
      " [-1.1779407  -1.2238635  -1.3783392  ...  1.8563395   0.7735903\n",
      "  -1.4703016 ]\n",
      " [ 0.8597378  -0.92469686 -1.6713753  ...  1.2039034  -0.13869023\n",
      "  -0.32454744]\n",
      " ...\n",
      " [-0.60446197 -0.6799242  -0.6457491  ...  0.8994331   0.09629128\n",
      "   0.67473245]\n",
      " [ 0.79872924  2.4295955  -0.09630711 ... -0.18796012 -0.7054102\n",
      "  -0.58494616]\n",
      " [-0.6288659   0.6889898   0.965949   ... -1.2318579  -1.1477281\n",
      "   0.4891984 ]]\n",
      "(89, 13)\n"
     ]
    }
   ],
   "source": [
    "###test set\n",
    "with open('wine_test.csv', newline='') as f:\n",
    "    reader_t = csv.reader(f)\n",
    "    data_t = list(reader_t)\n",
    "\n",
    "data_array_t = np.asarray(data_t, dtype=np.float32)\n",
    "data_unnorm_t = copy.deepcopy(data_array_t)\n",
    "\n",
    "data_fea_unnorm_t = data_unnorm_t[:,0:13]\n",
    "print(np.shape(data_fea_unnorm_t))\n",
    "\n",
    "data_fea_norm_t = copy.deepcopy(data_fea_unnorm_t)\n",
    "\n",
    "data_fea_norm_t = sc_X.transform(data_fea_norm_t)     #\tFit to data, then transform it using \n",
    "print('After standardization:') \n",
    "print(data_fea_norm_t)\n",
    "print(np.shape(data_fea_norm_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 2)\n",
      "(89,)\n",
      "feature_2_t's final Weight:\n",
      "[[ 2.37373081 -1.36891671]\n",
      " [-2.06208771  0.60739965]\n",
      " [ 0.70203731  0.90656301]]\n",
      "mean accuracy is 0.7078651685393258\n"
     ]
    }
   ],
   "source": [
    "#take first tow columns\n",
    "feature_2_t = data_fea_norm_t[:,0:2]\n",
    "print(np.shape(feature_2_t))\n",
    "class_labels_t = data_unnorm_t[:,13]\n",
    "print(np.shape(class_labels_t))\n",
    "#print(class_labels_t)\n",
    "\n",
    "perceptron_t = Perceptron(max_iter=1000, tol=0.0001, random_state = None) \n",
    "#use weight in training data as starting weight\n",
    "perceptron_t.fit(feature_2_t, class_labels_t, coef_init = final_wei1)      \n",
    "print(\"feature_2_t's final Weight:\")\n",
    "print(perceptron_t.coef_)\n",
    "\n",
    "label_train_pred1_t = perceptron_t.predict(feature_2_t)      #Predict class labels for samples in X.\n",
    "#print(label_train_pred1_t)\n",
    "\n",
    "mean_accuracy1_t = perceptron_t.score(feature_2_t, class_labels_t)    #Returns the mean accuracy on the given test data and labels.\n",
    "print(\"mean accuracy is \" + str(mean_accuracy1_t))\n",
    "mean_ac3 = calcul_accuracy(label_train_pred1_t, class_labels_t)\n",
    "#print(calcul_accuracy(label_train_pred1_t, class_labels_t))\n",
    "#print(mean_ac3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_all's final Weight:\n",
      "[[ 4.47718757  0.47141428  1.02274498 -6.91340923 -0.7776438  -1.32462251\n",
      "   2.49404704 -1.01948577 -0.20688564 -0.25636744 -0.02023274  0.4750878\n",
      "   6.29118815]\n",
      " [-6.28001904 -5.21275248 -4.24778601  3.83689271 -0.84082723 -0.03437197\n",
      "   4.3333978  -0.20464438  2.17821469 -6.68368795  2.79115524  0.23870879\n",
      "  -7.85211759]\n",
      " [ 4.03230448 -0.01813136  4.34244732  4.0959706  -1.73706185 -1.36960012\n",
      "  -5.56337938  0.23361239 -0.4909647   6.4652195  -4.0774564  -3.14592427\n",
      "  -0.48663856]]\n",
      "mean accuracy is 1.0\n",
      "1.0\n",
      "interation times: \n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#all_features_test = data_fea_norm_t[:,0:13]\n",
    "\n",
    "###all features for test\n",
    "perceptron_t.fit(data_fea_norm_t, class_labels_t, coef_init = final_wei2)\n",
    "print(\"feature_all's final Weight:\")\n",
    "print(perceptron_t.coef_)\n",
    "label_train_pred2_t = perceptron_t.predict(data_fea_norm_t)      #Predict class labels for samples in X.\n",
    "#print(label_train_pred2_t)\n",
    "mean_accuracy2_t = perceptron_t.score(data_fea_norm_t, class_labels_t)\n",
    "print(\"mean accuracy is \" + str(mean_accuracy2_t))\n",
    "mean_ac3 = calcul_accuracy(label_train_pred2_t, class_labels_t)\n",
    "print(mean_ac3)\n",
    "print('interation times: ')\n",
    "print(perceptron_t.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.66895051 -0.88679077]\n",
      " [-3.56210582 -2.02978359]\n",
      " [ 0.3848902   0.80094763]]\n",
      "0.8426966292134831\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n    perceptron1.fit(feature_2, class_labels, coef_init = random_w)\\n    label1_train_pred = perceptron1.predict(feature_2) \\n    acc_train1 = perceptron1.score(feature_2, class_labels) \\n    if(acc_train1 > accu_tmp1):\\n        accu_tmp1 = acc_train1 \\n        Weight1 = perceptron1.coef_ \\n        ini_weight1 = random_w\\n'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d\n",
    "epoch = 100\n",
    "Weight1 = np.zeros((3,2)) \n",
    "accu_tmp1 = 0\n",
    "#perceptron1 = Perceptron(max_iter=1000, tol=0.0001, random_state = None)   \n",
    "for i in range(epoch):   \n",
    "    perceptron1 = Perceptron(max_iter=1000, tol=0.0001, random_state = None)   \n",
    "    random_w1 = np.random.randn(3,2)\n",
    "    perceptron1.fit(feature_2, class_labels, coef_init = random_w1)\n",
    "    label1_train_pred = perceptron1.predict(feature_2) \n",
    "    acc_train1 = perceptron1.score(feature_2, class_labels) \n",
    "    if(acc_train1 > accu_tmp1):\n",
    "        accu_tmp1 = acc_train1 \n",
    "        Weight1 = perceptron1.coef_ \n",
    "        #ini_weight1 = random_w1      \n",
    "\"\"\"\n",
    "    random_w2 = np.random.randn(3,13)\n",
    "    perceptron1.fit(data_fea_norm, class_labels, coef_init = random_w2)\n",
    "    label2_train_pred = perceptron1.predict(data_fea_norm) \n",
    "    acc_train2 = perceptron1.score(data_fea_norm, class_labels) \n",
    "    if(acc_train2 > accu_tmp2):\n",
    "        accu_tmp2 = acc_train2 \n",
    "        Weight2 = perceptron1.coef_\n",
    "        ini_weight2 = random_w2          \n",
    "\"\"\"                       \n",
    "print(Weight1)\n",
    "print(accu_tmp1)\n",
    "print(perceptron1.n_iter_)\n",
    "#print(Weight2)       #two are the same\n",
    "#print(accu_tmp2)\n",
    "\"\"\" \n",
    "    perceptron1.fit(feature_2, class_labels, coef_init = random_w)\n",
    "    label1_train_pred = perceptron1.predict(feature_2) \n",
    "    acc_train1 = perceptron1.score(feature_2, class_labels) \n",
    "    if(acc_train1 > accu_tmp1):\n",
    "        accu_tmp1 = acc_train1 \n",
    "        Weight1 = perceptron1.coef_ \n",
    "        ini_weight1 = random_w\n",
    "\"\"\"      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7191011235955056\n",
      "[[ 1.56519354 -1.15876042]\n",
      " [-1.78066846 -0.40702914]\n",
      " [ 1.20334998  1.71657481]]\n",
      "[[ 1.56519354 -1.15876042]\n",
      " [-1.78066846 -0.40702914]\n",
      " [ 1.20334998  1.71657481]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nperceptron1.fit(data_fea_norm_t, class_labels_t, coef_init = ini_weight2)    #use best training initiate weight\\ntest_label2 = perceptron1.predict(data_fea_norm_t) \\nacc_test2 = perceptron1.score(data_fea_norm_t, class_labels_t) \\nprint(acc_test2)\\nprint(perceptron1.coef_)\\n'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron1.fit(feature_2_t, class_labels_t, coef_init=Weight1)    #use best training initiate weight\n",
    "\n",
    "test_label1 = perceptron1.predict(feature_2_t) \n",
    "acc_test1 = perceptron1.score(feature_2_t, class_labels_t) \n",
    "print(acc_test1)\n",
    "\n",
    "print(Weight1)\n",
    "print(perceptron1.coef_)\n",
    "#print(perceptron1.n_iter_)\n",
    "\n",
    "\"\"\"\n",
    "perceptron1.fit(data_fea_norm_t, class_labels_t, coef_init = ini_weight2)    #use best training initiate weight\n",
    "test_label2 = perceptron1.predict(data_fea_norm_t) \n",
    "acc_test2 = perceptron1.score(data_fea_norm_t, class_labels_t) \n",
    "print(acc_test2)\n",
    "print(perceptron1.coef_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all features weight is [[ 1.01030482  1.54174978  2.77978482 -1.55356436  0.57699227  0.04844588\n",
      "   3.4095022  -0.94332465  1.08950633  0.2755902   1.05142774  1.62093587\n",
      "   5.22989665]\n",
      " [-6.51245126 -5.34977134 -3.07745092  3.42743264 -1.74338091  0.84682193\n",
      "   1.5153428   4.37073861  0.30830707 -9.70154192  0.92117845 -0.03401687\n",
      "  -8.34531583]\n",
      " [ 1.99192419  0.71000519  1.78091195  0.58691982 -0.78281875 -1.16437171\n",
      "  -1.83762887 -1.86581723 -2.63176456  6.75446012 -4.33757414 -1.6259074\n",
      "  -1.0461937 ]]\n",
      "accuracy for training data is 1.0\n",
      "1.0\n",
      "[[ 5.04307009  0.8263439   2.56145945 -3.58962026 -1.0203604   0.30702461\n",
      "   1.58867804 -0.4027867   1.7695967  -0.82391448  1.20664478  0.66082896\n",
      "   6.05001039]\n",
      " [-5.67367783 -5.47156187 -4.59792646  3.55384765 -1.32611607  1.4938021\n",
      "   4.28543857  1.67332319  2.99636363 -9.10341701  1.97685196  1.48432944\n",
      "  -8.14080565]\n",
      " [ 4.32432391  0.81605765  1.5149818   3.50434864 -1.93695515 -2.4682778\n",
      "  -5.17082157 -0.52633802  0.69355963  8.5851582  -1.05314481 -2.78629444\n",
      "  -0.01243363]]\n"
     ]
    }
   ],
   "source": [
    "Weight2 = np.zeros((3,13))\n",
    "#ini_weight2 = np.zeros((3,13))\n",
    "accu_tmp2 = 0\n",
    "perceptron2 = Perceptron(max_iter=1000, tol=0.0001, random_state = None)     ##????为什么放进循环  \n",
    "for i in range(100): \n",
    "    \n",
    "    random_w2 = np.random.randn(3,13)\n",
    "    perceptron2.fit(data_fea_norm, class_labels, coef_init = random_w2)\n",
    "    label2_train_pred = perceptron2.predict(data_fea_norm) \n",
    "    acc_train2 = perceptron2.score(data_fea_norm, class_labels) \n",
    "    if(acc_train2 > accu_tmp2):\n",
    "        accu_tmp2 = acc_train2 \n",
    "        Weight2 = perceptron2.coef_\n",
    "    \n",
    "print('all features weight is ' + str(Weight2))\n",
    "print('accuracy for training data is ' + str(accu_tmp2))\n",
    "\n",
    "perceptron2.fit(all_features_test, class_labels_t, coef_init = Weight2)    #use best training initiate weight\n",
    "test_label2 = perceptron2.predict(data_fea_norm_t) \n",
    "acc_test2 = perceptron2.score(data_fea_norm_t, class_labels_t) \n",
    "print(acc_test2)\n",
    "print(perceptron2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
